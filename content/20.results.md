## Results

BioChatter is a python framework that provides an easy-to-use interface to interact with LLMs and auxiliary technologies via an intuitive API (application programming interface).
This way, its functionality can be integrated into any number of user interfaces, such as web apps, command line interfaces, or Jupyter notebooks.
The framework is designed to be composable, meaning that any of its components can be exchanged with other implementations, for instance, to use a different LLM or knowledge graph (KG).
Functionalities include:

- **basic question answering** (QA) with LLMs hosted by providers (such as OpenAI) as well as local open-source models

- **benchmarking** of LLMs, prompts, and other components

- **knowledge graph querying** with automated synchronisation of biochatter with any KG created in the BioCypher framework [@biocypher]

- **retrieval augmented generation** using vector database embeddings of user-provided literature

- **model chaining** to orchestrate multiple LLMs and other models in a single conversation using the LangChain framework [@langchain]

- **fact-checking** of LLM responses using a second LLM

In the following, we briefly describe these components, which are demonstrated in the ChatGSE web app (https://chat.biocypher.org).

### Question Answering and LLM connectivity

The core functionality of BioChatter is to interact with LLMs.
The framework supports both leading proprietary models such as the GPT series from OpenAI as well as open-source models such as LLaMA2 [] via a flexible open-source deployment framework [].
Currently, the most powerful conversational AI platform, ChatGPT (OpenAI), is surrounded by data privacy concerns [@{https://www.reuters.com/technology/european-data-protection-board-discussing-ai-policy-thursday-meeting-2023-04-13/}].
We address this issue in two ways.
Firstly, we provide access to the OpenAI models through their API, which is subject to different, more stringent data protection than the web interface [@{https://openai.com/policies/terms-of-use}], most importantly by disallowing reuse of user inputs for subsequent model training.
Secondly, we aim to preferentially support open-source LLMs to facilitate more transparency in their application and increase data privacy by being able to run a model locally on dedicated hardware and end-user devices [@doi:10.1038/d41586-023-01295-4].
By building on LangChain [@langchain], we support dozens of LLM providers, such as the Hugging Face API, which can be used to query any of the more than 100 000 open-source models on Hugging Face Hub [@{https://huggingface.co/docs/hub/index}], for instance those on its LLM leaderboard [@{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}].
Although OpenAIâ€™s models currently vastly outperform any alternatives in terms of both LLM performance and API convenience, we expect many open-source developments in this area in the future.
Therefore, we support plug-and-play exchange of models to enhance biomedical AI-readiness, and we implement a bespoke benchmarking framework for the biomedical application of LLMs.

### Benchmarking