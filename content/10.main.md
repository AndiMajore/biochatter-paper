## Main

Despite our technological advances, biology and biomedicine continue to pose incredible challenges [@{https://www.bbc.com/news/health-65252510}].
We measure more and more data points with ever-increasing resolution to such a degree that their analysis and interpretation have become the bottleneck for their exploitation.
One reason for this challenge may be the inherent limitation of human knowledge [@doi:10.1016/j.tics.2005.04.010].
Even seasoned domain experts cannot know the implications of every molecule, be it metabolite, DNA, RNA, or protein, even in their own domain.
In addition, biological events are context-dependent, for instance with respect to a cell type or specific disease.

Large Language Models (LLMs) of the current generation, on the other hand, can access enormous amounts of knowledge, encoded (incomprehensibly) in their billions of parameters [@doi:10.48550/arxiv.2204.02311; @10.48550/arxiv.2201.08239; @10.48550/arxiv.2303.08774].
Trained correctly, they can recall and combine virtually limitless knowledge from their training set.
ChatGPT has taken the world by storm, and many biomedical researchers already use LLMs in their daily work, for general as well as bioinformatics-specific tasks [@doi:10.1101/2023.04.16.537094; @doi:10.1038/s41587-023-01789-6].
However, the current, predominantly manual, way of interacting with LLMs is virtually non-reproducible, and their behaviour can be erratic.
For instance, they are known to hallucinate: they make up facts as they go along, and, to make matters worse, are convinced - and convincing - regarding the truth of their hallucinations [@doi:10.1038/s41586-023-05881-4; @doi:10.1038/s41587-023-01789-6].
While current efforts towards AGI (Artificial General Intelligence) manage to ameliorate some of the shortcomings by ensembling multiple models [@{https://python.langchain.com}] with long-term memory stores [@{https://autogpt.net/}], the current generation of AI does not inspire adequate trust to be applied to biomedical problems without supervision [@doi:10.1038/s41586-023-05881-4].
Additionally, biomedicine demands greater care in data privacy, licensing, and transparency than most other real-world issues.

A major aim of computational biology is to distil high-dimensional molecular measurements into a humanly digestible form by projecting the measurements into a lower-dimensional space composed of gene programs, pathways, or other functional groupings of biological entities, for example via gene set enrichment analyses.
However, even this distilled knowledge requires advanced expertise and thorough literature research to effectively interpret and exploit, and benchmarking the methods’ performance is non-trivial [@doi:10.1093/bib/bbz158].

To improve and accelerate this interpretation and exploration, we have developed BioChatter, a platform for communicating with LLMs specifically tuned to biomedical research, the use of which we demonstrate in a conversational web interface, ChatGSE (Figure @fig:overview).
The platform guides the human researcher intuitively through the interaction with the model, while counteracting the problematic behaviours of the LLM.
Since the interaction is mainly based on plain text, it can be used by virtually any researcher.
We engineer prompts around the queries of the user to improve model performance with regard to biomedicine, and automate the integration of popular bioinformatics methods, such as differential expression and gene set enrichment (Supplementary Note [Prompt Engineering]).

<!-- Figure 1 -->
![
**The ChatGSE composable platform architecture (simplified).**
The user submits a question about a topic of interest (e.g., an experiment) along with the low-dimensional results of a bioinformatics analysis (top left).
The platform’s main response circuit (blue) composes a number of specifically engineered prompts and passes them (and a conversation history) to the primary LLM, which generates a response for the user based on all inputs.
This response is simultaneously used to prompt the secondary circuit (orange), which fulfils auxiliary tasks to complement the primary response.
In particular, using search, the secondary circuit queries a database as prior knowledge repository and compares annotations to the primary response.
The knowledge graph can also serve as long-term memory extension of the model.
Further, an independent LLM receives the primary response for fact-checking, which can be supplemented with context-specific information by a document summarisation model.
If this “second opinion” differs from the primary response, a warning is issued.
The platform is composable in all aspects, in principle allowing arbitrary extensions to other, specialised models for additional tasks orchestrated by the primary LLM.
](images/graphical_abstract.png "Overview"){#fig:overview}

On the model side, we implement several measures in addition to the prompt engineering around the user's queries.
For instance, we deploy a second model to safeguard the factual correctness of the primary LLM's responses (Supplementary Note [Correcting Agent]).
These interactions are handled by a pre-programmed conversational “Assistant,” which dynamically orchestrates LLM agents with distinct tasks using a Python model chaining framework [@{https://python.langchain.com}].
Using vector database approaches, the user’s prompts can be further supplemented with information extracted from pertinent, user-provided literature (Supplementary Note [In-context Learning]).

To increase data-awareness of the AI agents, we introduce connectivity to databases, which can extend the long-term memory of the models, semantically ground the biological entities with respect to suitable ontologies, and compare the model's responses to prior knowledge ground truth.
By integrating a flexible knowledge graph creation framework [@doi:10.1038/s41587-023-01848-y], we allow versatile use cases across the entire research spectrum.
For example, connecting to a knowledge graph of cell markers based on Cell Ontology [doi:10.1186/s13326-016-0088-7], the task of annotating single cell data sets can be automated and made more reproducible (Supplementary Note [Cell Type Annotation]) by abstracting the pioneering efforts of manually executed studies [@doi:10.1101/2023.04.16.537094].
We engineer the prompts around knowledge graph queries around the semantic configuration of BioCypher knowledge graphs, which allows efficient communication of the LLM with the knowledge graph and avoids hallucination-based issues.
This allows querying any knowledge graph using natural language as well as the development of advanced multi-stage reasoning strategies (Supplementary Note [Knowledge Graphs]).

<!-- TODO BENCHMARKING SECTION -->

Currently, the most powerful conversational AI platform, ChatGPT (OpenAI), is surrounded by data privacy concerns [@{https://www.reuters.com/technology/european-data-protection-board-discussing-ai-policy-thursday-meeting-2023-04-13/}].
We address this issue in two ways.
Firstly, we provide access to the OpenAI models through the API (Application Programming Interface), which is subject to different, more stringent data protection than the web interface [@{https://openai.com/policies/terms-of-use}].
Secondly, we aim to preferentially support open-source LLMs to facilitate more transparency in their application and increase data privacy by being able to run a model locally [@doi:10.1038/d41586-023-01295-4].
Our orchestration tool supports dozens of LLM providers [@{https://python.langchain.com}], such as the Hugging Face API, which can be used to query the recently released open-source ChatGPT-alternative HuggingChat or any other of the more than 100 000 open-source models on Hugging Face Hub [@{https://huggingface.co/docs/hub/index}].
Hugging Face also provide an open LLM leaderboard with up-to-date benchmarks of open-source LLMs [@{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}].
Although OpenAI’s models currently vastly outperform any alternatives in terms of both LLM performance and API convenience, we expect many open-source developments in this area in the future.
Therefore, we support plug-and-play exchange of models to enhance biomedical AI-readiness.

In response to the urgent need to protect confidential biomedical data, we sought a way to create a robust framework that ensures data privacy while enabling personalised interactions. At its core, we have created a system of two key components: WebLLM [@{https://github.com/mlc-ai/web-llm}] and ChatGSE Next [@{https://github.com/biocypher/chatgse-next}]. WebLLM hosts a local LLM itself, which is accessed by the BioChatter server within ChatGSE Next. This combination creates a secure conversational environment and minimises the risks associated with data breaches. Hosting local LLMs using WebLLM allows them to run without an internet connection in a WebAssembly module. This architecture thus enables complete data security and combines this with the aforementioned applications for LLMs in biomedical research and is limited only by the resources of the host computer.

In the future, we aim to integrate biological prior knowledge representation with LLM reasoning.
Using the emergent strategies of in-context learning, instruction learning, and chain-of-thought prompting [@doi:10.48550/arxiv.2303.17580], this can enable causal inference on relationships between biological entities, for instance via protein-protein interactions (Supplementary Note [Causal Inference]), and automated validation of literature references provided by the LLM (Supplementary Note [Literature Reference Database]).
While the current models do not yet appear suited for unsupervised reasoning in the biomedical space, they can already save much time otherwise spent on web and literature searches.
Additionally, the ChatGSE platform provides a reproducible environment for benchmarking of models and engineered prompts to gauge their biomedical reliability.
The ability to chain arbitrary types of models enables advanced applications, for instance connecting to visual modalities such as spatial omics.
We provide further details and application scenarios in our Supplementary Notes.

While we focus on the biomedical field, the concept of the tool can easily be extended to other scientific domains by adjusting domain-specific prompts and data inputs, which in our framework are accessible in a composable and user-friendly manner.
The Python library to interact with LLMs, vector databases, and all other features is developed openly on GitHub (https://github.com/biocypher/biochatter), and can be integrated into any number of user interface solutions apart from our own, for instance, INDRA [@doi:10.15252/msb.20177651] and drugst.one [@doi:10.48550/arxiv.2305.15453].
We develop under the permissive MIT licence and encourage contributions and suggestions from the community with regard to the addition of bioinformatics tool inputs, prompt engineering, safeguarding mechanisms, and any other feature.

